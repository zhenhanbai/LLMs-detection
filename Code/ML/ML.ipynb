{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、导入本次实验需要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import classification_report, roc_curve, roc_auc_score, f1_score, make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from scipy.stats import expon, reciprocal\n",
    "import sys\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG, \n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger('training')\n",
    "file_handler = logging.FileHandler('../../Result/ML/train.log') \n",
    "file_handler.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "file_handler.setFormatter(formatter)\n",
    "logger.addHandler(file_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、使用TF-IDF进行数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "2023-12-12 16:01:44,024 - jieba - DEBUG - Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "2023-12-12 16:01:44,026 - jieba - DEBUG - Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.613 seconds.\n",
      "2023-12-12 16:01:44,639 - jieba - DEBUG - Loading model cost 0.613 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "2023-12-12 16:01:44,641 - jieba - DEBUG - Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "def data_process(file_name):\n",
    "    data = pd.read_csv(file_name, encoding='utf-8')\n",
    "    data = data[['answer', 'label']]\n",
    "    data['answer'] = data['answer'].apply(lambda x: ' '.join(jieba.cut(x)))\n",
    "    return data['answer'], data['label']\n",
    "\n",
    "X_train, y_train = data_process(\"../../data/zh_doc_train.csv\")\n",
    "X_test, y_test = data_process(\"../../data/zh_doc_test.csv\")\n",
    "X_sent_test, y_sent_test = data_process('../../data/shuffled_zh_sent_test.csv')\n",
    "X_concat_test, y_concat_test = pd.concat([X_test, X_sent_test], axis=0), pd.concat([y_test, y_sent_test], axis=0)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test = tfidf_vectorizer.transform(X_test)\n",
    "X_sent_test = tfidf_vectorizer.transform(X_sent_test)\n",
    "X_concat_test = tfidf_vectorizer.transform(X_concat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3、使用RandomizedSearchCV逐个进行调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "        LogisticRegression(),\n",
    "        GaussianNB(),\n",
    "        KNeighborsClassifier(),\n",
    "        DecisionTreeClassifier(),\n",
    "        SVC(),\n",
    "        RandomForestClassifier(),\n",
    "        GradientBoostingClassifier(),\n",
    "        XGBClassifier(),\n",
    "        LGBMClassifier(),\n",
    "        CatBoostClassifier()\n",
    "    ]\n",
    "# 使用f1评分\n",
    "scorer = make_scorer(f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1、逻辑回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "param_distributions = {\n",
    "    'C': reciprocal(0.1, 100),\n",
    "    'solver': ['liblinear', 'newton-cg', 'lbfgs'],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "random_search = RandomizedSearchCV(classifiers[0], param_distributions, n_iter=100, cv=5, scoring=scorer, random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "logger.info(classifiers[0].__class__.__name__)\n",
    "logger.info(\"最佳参数: %s\", random_search.best_params_)\n",
    "logger.info(\"最佳模型分数（F1分数）: %s\", random_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-12 15:59:30,854 - training - INFO - dataset doc F1分数: 0.9516055788355426\n",
      "2023-12-12 15:59:30,981 - training - INFO - dataset sent F1分数: 0.790188538643597\n",
      "2023-12-12 15:59:31,081 - training - INFO - dataset mix F1分数: 0.8186839651235414\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(C=62.10, penalty='l2',solver='liblinear',max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "eval_name = ['doc', 'sent', 'mix']\n",
    "\n",
    "def eval(X_test, y_test, eval_name):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = [1 if x > 0.5 else 0 for x in y_pred]\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    logger.info(\"dataset {} F1分数: {}\".format(eval_name, report['weighted avg']['f1-score']))\n",
    "\n",
    "eval(X_test=X_test, y_test=y_test, eval_name=eval_name[0])\n",
    "eval(X_test=X_sent_test, y_test=y_sent_test, eval_name=eval_name[1])\n",
    "eval(X_test=X_concat_test, y_test=y_concat_test, eval_name=eval_name[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2、朴素贝叶斯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianNB()\n",
    "model.fit(X_train.toarray(), y_train)\n",
    "eval_name = ['doc', 'sent', 'mix']\n",
    "logger.info(classifiers[1].__class__.__name__)\n",
    "\n",
    "def eval(X_test, y_test, eval_name):\n",
    "    y_pred = model.predict(X_test.toarray())\n",
    "    y_pred = [1 if x > 0.5 else 0 for x in y_pred]\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    logger.info(\"dataset {} F1分数: {}\".format(eval_name, report['weighted avg']['f1-score']))\n",
    "\n",
    "eval(X_test=X_test, y_test=y_test, eval_name=eval_name[0])\n",
    "eval(X_test=X_sent_test, y_test=y_sent_test, eval_name=eval_name[1])\n",
    "eval(X_test=X_concat_test, y_test=y_concat_test, eval_name=eval_name[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-12 15:55:26,483 - training - INFO - LogisticRegression\n",
      "2023-12-12 15:55:26,484 - training - INFO - 最佳参数: {'n_neighbors': 96}\n",
      "2023-12-12 15:55:26,486 - training - INFO - 最佳模型分数（F1分数）: 0.7478112144870892\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    # \"n_neighbors\" : range(1, 21, 2),\n",
    "    # \"n_neighbors\" : range(19, 50, 2),\n",
    "    \"n_neighbors\" : range(50, 100, 2),\n",
    "}\n",
    "grid_search = GridSearchCV(classifiers[2], parameters, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "logger.info(classifiers[0].__class__.__name__)\n",
    "logger.info(\"最佳参数: %s\", grid_search.best_params_)\n",
    "logger.info(\"最佳模型分数（F1分数）: %s\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-12 15:57:49,338 - training - INFO - KNeighborsClassifier\n",
      "2023-12-12 15:58:05,146 - training - INFO - dataset doc F1分数: 0.8313328358840915\n",
      "2023-12-12 15:58:24,401 - training - INFO - dataset sent F1分数: 0.8110983500629481\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=96) \n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "eval_name = ['doc', 'sent', 'mix']\n",
    "logger.info(classifiers[2].__class__.__name__)\n",
    "\n",
    "def eval(X_test, y_test, eval_name):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = [1 if x > 0.5 else 0 for x in y_pred]\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    logger.info(\"dataset {} F1分数: {}\".format(eval_name, report['weighted avg']['f1-score']))\n",
    "\n",
    "eval(X_test=X_test, y_test=y_test, eval_name=eval_name[0])\n",
    "eval(X_test=X_sent_test, y_test=y_sent_test, eval_name=eval_name[1])\n",
    "eval(X_test=X_concat_test, y_test=y_concat_test, eval_name=eval_name[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3、决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'max_depth': np.arange(10, 27, 2),\n",
    "    'min_samples_split': np.arange(2, 10),\n",
    "    'min_samples_leaf': np.arange(1, 5),\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "grid_search = GridSearchCV(classifiers[3], parameters, cv=5, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "logger.info(classifiers[3].__class__.__name__)\n",
    "logger.info(\"最佳参数: %s\", grid_search.best_params_)\n",
    "logger.info(\"最佳模型分数（F1分数）: %s\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 下面参数过拟合了，在OOV上还没有默认参数效果好\n",
    "model = DecisionTreeClassifier(criterion='entropy', max_depth=26, min_samples_leaf=3, min_samples_split=9)\n",
    "model.fit(X_train, y_train)\n",
    "eval_name = ['doc', 'sent', 'mix']\n",
    "\n",
    "def eval(X_test, y_test, eval_name):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = [1 if x > 0.5 else 0 for x in y_pred]\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    logger.info(\"dataset {} F1分数: {}\".format(eval_name, report['weighted avg']['f1-score']))\n",
    "\n",
    "eval(X_test=X_test, y_test=y_test, eval_name=eval_name[0])\n",
    "eval(X_test=X_sent_test, y_test=y_sent_test, eval_name=eval_name[1])\n",
    "eval(X_test=X_concat_test, y_test=y_concat_test, eval_name=eval_name[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4、SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 搜索kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    # 'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    # 'gamma': [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "grid_search = GridSearchCV(classifiers[4], parameters, cv=5, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "logger.info(classifiers[4].__class__.__name__)\n",
    "logger.info(\"最佳参数: %s\", grid_search.best_params_)\n",
    "logger.info(\"最佳模型分数（F1分数）: %s\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-12 16:05:04,015 - training - INFO - dataset sent F1分数: 0.7892086042699143\n"
     ]
    }
   ],
   "source": [
    "model = SVC(kernel='linear', C=1)\n",
    "model.fit(X_train, y_train)\n",
    "eval_name = ['doc', 'sent', 'mix']\n",
    "\n",
    "def eval(X_test, y_test, eval_name):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = [1 if x > 0.5 else 0 for x in y_pred]\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    logger.info(\"dataset {} F1分数: {}\".format(eval_name, report['weighted avg']['f1-score']))\n",
    "\n",
    "# eval(X_test=X_test, y_test=y_test, eval_name=eval_name[0])\n",
    "eval(X_test=X_sent_test, y_test=y_sent_test, eval_name=eval_name[1])\n",
    "# eval(X_test=X_concat_test, y_test=y_concat_test, eval_name=eval_name[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 搜索正则"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = {\n",
    "    'C': reciprocal(0.1, 500),\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(classifiers[5], param_distributions, n_iter=30, verbose=2, cv=5, scoring=scorer, random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "logger.info(classifiers[5].__class__.__name__)\n",
    "logger.info(\"最佳参数: %s\", random_search.best_params_)\n",
    "logger.info(\"最佳模型分数（F1分数）: %s\", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel='linear', )\n",
    "model.fit(X_train, y_train)\n",
    "eval_name = ['doc', 'sent', 'mix']\n",
    "\n",
    "def eval(X_test, y_test, eval_name):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = [1 if x > 0.5 else 0 for x in y_pred]\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    logger.info(\"dataset {} F1分数: {}\".format(eval_name, report['weighted avg']['f1-score']))\n",
    "\n",
    "eval(X_test=X_test, y_test=y_test, eval_name=eval_name[0])\n",
    "eval(X_test=X_sent_test, y_test=y_sent_test, eval_name=eval_name[1])\n",
    "eval(X_test=X_concat_test, y_test=y_concat_test, eval_name=eval_name[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5、RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = {\n",
    "    'n_estimators': np.arange(100, 401, 50),\n",
    "    'max_depth': np.arange(15, 40, 2),\n",
    "    'min_samples_split': np.arange(2, 4),\n",
    "    'min_samples_leaf': np.arange(1, 4)\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(classifiers[5], param_distributions, n_iter=100, verbose=2, cv=5, scoring=scorer, random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "logger.info(classifiers[5].__class__.__name__)\n",
    "logger.info(\"最佳参数: %s\", random_search.best_params_)\n",
    "logger.info(\"最佳模型分数（F1分数）: %s\", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 模型过拟合，没有默认参数好\n",
    "model = RandomForestClassifier(n_estimators=500, min_samples_split=3, min_samples_leaf=1, max_depth=30)\n",
    "model.fit(X_train, y_train)\n",
    "eval_name = ['doc', 'sent', 'mix']\n",
    "\n",
    "def eval(X_test, y_test, eval_name):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = [1 if x > 0.5 else 0 for x in y_pred]\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    logger.info(\"dataset {} F1分数: {}\".format(eval_name, report['weighted avg']['f1-score']))\n",
    "\n",
    "eval(X_test=X_test, y_test=y_test, eval_name=eval_name[0])\n",
    "eval(X_test=X_sent_test, y_test=y_sent_test, eval_name=eval_name[1])\n",
    "eval(X_test=X_concat_test, y_test=y_concat_test, eval_name=eval_name[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6、GBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = {\n",
    "    'n_estimators': np.arange(100, 301, 50),\n",
    "    'max_depth': np.arange(6, 15),\n",
    "    'learning_rate': np.linspace(0.01, 0.2, 10),\n",
    "    'min_samples_split': np.arange(2, 5),\n",
    "    'min_samples_leaf': np.arange(1, 4),\n",
    "    'subsample': np.linspace(0.6, 1, 5)\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(classifiers[6], param_distributions, n_iter=100, verbose=2, cv=5, scoring=scorer, random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "logger.info(classifiers[6].__class__.__name__)\n",
    "logger.info(\"最佳参数: %s\", random_search.best_params_)\n",
    "logger.info(\"最佳模型分数（F1分数）: %s\", random_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 模型过拟合，没有默认参数好\n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "eval_name = ['doc', 'sent', 'mix']\n",
    "\n",
    "def eval(X_test, y_test, eval_name):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = [1 if x > 0.5 else 0 for x in y_pred]\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    logger.info(\"dataset {} F1分数: {}\".format(eval_name, report['weighted avg']['f1-score']))\n",
    "\n",
    "eval(X_test=X_test, y_test=y_test, eval_name=eval_name[0])\n",
    "eval(X_test=X_sent_test, y_test=y_sent_test, eval_name=eval_name[1])\n",
    "eval(X_test=X_concat_test, y_test=y_concat_test, eval_name=eval_name[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.7、XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = {\n",
    "    'n_estimators': np.arange(50, 400, 50),\n",
    "    'learning_rate': np.linspace(0.001, 0.1, 10),\n",
    "    'max_depth': np.arange(3, 10),\n",
    "    'colsample_bytree': np.linspace(0.5, 1, 5),\n",
    "    'subsample': np.linspace(0.6, 1, 5),\n",
    "    'booster': ['gbtree', 'gblinear', 'dart'],\n",
    "    'tree_method': ['auto', 'exact', 'approx', 'hist']\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(XGBClassifier(), param_distributions, n_iter=100, verbose=2, cv=5, scoring=scorer, random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "logger.info(classifiers[7].__class__.__name__)\n",
    "logger.info(\"最佳参数: %s\", random_search.best_params_)\n",
    "logger.info(\"最佳模型分数（F1分数）: %s\", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "eval_name = ['doc', 'sent', 'mix']\n",
    "\n",
    "def eval(X_test, y_test, eval_name):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = [1 if x > 0.5 else 0 for x in y_pred]\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    logger.info(\"dataset {} F1分数: {}\".format(eval_name, report['weighted avg']['f1-score']))\n",
    "\n",
    "eval(X_test=X_test, y_test=y_test, eval_name=eval_name[0])\n",
    "eval(X_test=X_sent_test, y_test=y_sent_test, eval_name=eval_name[1])\n",
    "eval(X_test=X_concat_test, y_test=y_concat_test, eval_name=eval_name[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.8、LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distributions = {\n",
    "    'n_estimators': np.arange(50, 400, 50),\n",
    "    'learning_rate': np.linspace(0.001, 0.1, 10),\n",
    "    'max_depth': np.arange(3, 10),\n",
    "    'colsample_bytree': np.linspace(0.5, 1, 5),\n",
    "    'subsample': np.linspace(0.6, 1, 5),\n",
    "    'boosting_type': ['gbtree', 'rf', 'dart', 'goss'],\n",
    "    'tree_method': ['auto', 'exact', 'approx', 'hist']\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(LGBMClassifier(), param_distributions, n_iter=4, verbose=2, cv=5, scoring=scorer, random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "logger.info(classifiers[8].__class__.__name__)\n",
    "logger.info(\"最佳参数: %s\", random_search.best_params_)\n",
    "logger.info(\"最佳模型分数（F1分数）: %s\", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "eval_name = ['doc', 'sent', 'mix']\n",
    "\n",
    "def eval(X_test, y_test, eval_name):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = [1 if x > 0.5 else 0 for x in y_pred]\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    logger.info(\"dataset {} F1分数: {}\".format(eval_name, report['weighted avg']['f1-score']))\n",
    "\n",
    "eval(X_test=X_test, y_test=y_test, eval_name=eval_name[0])\n",
    "eval(X_test=X_sent_test, y_test=y_sent_test, eval_name=eval_name[1])\n",
    "eval(X_test=X_concat_test, y_test=y_concat_test, eval_name=eval_name[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.9、CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(n_estimators=400)\n",
    "model.fit(X_train, y_train)\n",
    "eval_name = ['doc', 'sent', 'mix']\n",
    "\n",
    "def eval(X_test, y_test, eval_name):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = [1 if x > 0.5 else 0 for x in y_pred]\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    logger.info(\"dataset {} F1分数: {}\".format(eval_name, report['weighted avg']['f1-score']))\n",
    "\n",
    "eval(X_test=X_test, y_test=y_test, eval_name=eval_name[0])\n",
    "eval(X_test=X_sent_test, y_test=y_sent_test, eval_name=eval_name[1])\n",
    "eval(X_test=X_concat_test, y_test=y_concat_test, eval_name=eval_name[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM-Blender",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
